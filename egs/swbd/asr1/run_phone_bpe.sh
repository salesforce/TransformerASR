#!/bin/bash

# Copyright 2017 Johns Hopkins University (Shinji Watanabe)
# Copyright 2020 Salesforce Research (Weiran Wang)
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

. ./path.sh || exit 1;
. ./cmd.sh || exit 1;

# general configuration
backend=pytorch
stage=0        # start from 0 if you need to start from data preparation
stop_stage=100
ngpu=1         # number of gpus ("0" uses cpu, otherwise use gpu)
gpuid=
ncpu=64        # number of cpus, depends on the machine type you get
debugmode=1
verbose=0      # verbose option
resume=        # Resume the training from snapshot

# feature configuration
preprocess_config=conf/specaug_dsl.yaml

# training configuration
train_config=conf/train_largestoc5.yaml
maxepoch=150

# input subsampling
input_layer=conv2d
input_context=0
input_skiprate=1

# rnnlm related
rnnlm_config=conf/rnnlm.yaml
rnnlm_resume= # specify a snapshot file to resume LM training
lmtag=lm     # tag for managing LMs

# word-rnnlm related
word_rnnlm_config=conf/word_rnnlm.yaml
word_rnnlm_resume= # specify a snapshot file to resume LM training
word_rnnlm_beamsize=20
word_rnnlm_weight=0.4
subword_rnnlm_weight=0.0
word_rnnlm_bonus=0.0

model2_weight=0.4
num_decode=0

# decoding parameter
decode_config=conf/decode.yaml
# transformer-based model performs averaging of last 10 snapshot
n_average=10
lang_model=rnnlm.model.best # set a language model to be used for decoding

# bpemode (unigram or bpe)
nbpe=500
bpemode=phone_bpe
# number of bpes of the char system for joint decoding
nbpe_char=2000

# exp tag
tag="" # tag for managing experiments.

# decode set
decode_set="eval2000 rt03"

# The feature directory created by speech-datasets.
dumpdir=/export/home/speech-datasets/swbd/asr1/dump/fbank_pitch

# fisher_dir contains text file from the fisher dataset
fisher_dir=""

# which word RNNLM and lexicon for system ensemble
use_fisher_wordlm=false

. utils/parse_options.sh || exit 1;

# Set bash to 'debug' mode, it will exit on :
# -e 'error', -u 'undefined variable', -o ... 'error in pipeline', -x 'print commands',
set -e
set -u
set -o pipefail

export CUDA_VISIBLE_DEVICES=${gpuid}

train_set=swbd1_train
train_dev=swbd1_dev

# The training/dev/test fbank_pitch features are generated by the speech-datasets package,
# which alleviates us from generating the json files for inputs.
# This is done by going into the swbd/asr1/ folder of speech-datasets/, and running
# ./run.sh --feats_type fbank_pitch
# The dumpdir/ directory then contains ark features and text files.
# Also, change the path to cmvn.ark in your preprocess_config into the one prepared by speech-datasets.

mkdir -p data/lang_phone_bpe
dict=data/lang_phone_bpe/train_nodup_${bpemode}${nbpe}_units.txt
bpemodel=data/lang_phone_bpe/train_nodup_${bpemode}${nbpe}
echo "token dictionary: ${dict}"

# Obtain the list of all phones.
mkdir -p data/local/dict_phone
cat data/local/dict_nosp/silence_phones.txt data/local/dict_nosp/nonsilence_phones.txt data/local/dict_nosp/optional_silence.txt \
  | sort | uniq > data/local/dict_phone/phones.txt
# Convert the lexicon itself.
python convert_phone_and_alphabet.py --phonefile data/local/dict_phone/phones.txt --infile data/local/dict_nosp/lexicon.txt \
      --outfile data/lang_phone_bpe/lexicon_phone_converted.txt --in_separator " " --out_separator " "
for x in swbd1_train swbd1_dev eval2000 rt03; do
  # Change of <noise> to [noise] is to accommodate the bpe model which is trained with [noise].
  sed 's/them_1/them/g; s/<noise>/[noise]/g; s/<vocalized-noise>/[vocalized-noise]/g; s/<laughter>/[laughter]/g' \
  ${dumpdir}/${x}/text > ${dumpdir}/${x}/text_phone1
  python prep_ctc_trans.py data/local/dict_nosp/lexicon.txt ${dumpdir}/${x}/text_phone1 "<unk>" "_" > ${dumpdir}/${x}/text_phone
  python convert_phone_and_alphabet.py --phonefile data/local/dict_phone/phones.txt --infile ${dumpdir}/${x}/text_phone \
      --outfile ${dumpdir}/${x}/text_phone_converted --in_separator _ --out_separator " "
done
if [ -n "${fisher_dir}" ]; then
  echo "processing fisher text ..."
  sed 's/them_1/them/g; s/<noise>/[noise]/g; s/<vocalized-noise>/[vocalized-noise]/g; s/<laughter>/[laughter]/g' \
  ${fisher_dir}/text > ${fisher_dir}/text_phone1
  python prep_ctc_trans.py data/local/dict_nosp/lexicon.txt ${fisher_dir}/text_phone1 "<unk>" "_" > ${fisher_dir}/text_phone
  python convert_phone_and_alphabet.py --phonefile data/local/dict_phone/phones.txt --infile ${fisher_dir}/text_phone \
      --outfile ${fisher_dir}/text_phone_converted --in_separator _ --out_separator " "
fi

if [ ${stage} -le 2 ] && [ ${stop_stage} -ge 2 ]; then
    echo "stage 2: Dictionary Preparation"
    echo "<unk> 1" > ${dict} # <unk> must be 1, 0 will be used for "blank" in CTC
    
    echo "make a dictionary"
    cut -f 2- -d" " ${dumpdir}/${train_set}/text_phone_converted > data/lang_phone_bpe/input.txt

    # Please make sure sentencepiece is installed
    spm_train --input=data/lang_phone_bpe/input.txt \
            --model_prefix=${bpemodel} \
            --vocab_size=${nbpe} \
            --character_coverage=1.0 \
            --model_type=bpe \
            --model_prefix=${bpemodel} \
            --input_sentence_size=100000000 \
            --bos_id=-1 \
            --eos_id=-1 \
            --unk_id=0 \
            --user_defined_symbols="[laughter],[noise],[vocalized-noise]"

    spm_encode --model=${bpemodel}.model --output_format=piece < data/lang_phone_bpe/input.txt | tr ' ' '\n' | sort | uniq \
        | awk '{print $0 " " NR+1}' >> ${dict}
    wc -l ${dict}
fi


if [ -z ${lmtag} ]; then
    lmtag=$(basename ${rnnlm_config%.*})
fi
lmexpname=train_rnnlm_${backend}_${lmtag}_${bpemode}${nbpe}
lmexpdir=exp/${lmexpname}
mkdir -p ${lmexpdir}
echo "using token dictionary: ${dict}"

if [ ${stage} -le 3 ] && [ ${stop_stage} -ge 3 ]; then
    echo "stage 3: Token LM Preparation"
    lmdatadir=data/local/rnnlm_train_${bpemode}${nbpe}
    mkdir -p data/local/rnnlm_train ${lmdatadir}
    cut -f 2- -d" " ${dumpdir}/${train_set}/text_phone_converted | gzip -c > data/local/rnnlm_train/${train_set}_text.gz
    if [ -n "${fisher_dir}" ]; then
        cut -f 2- -d" " ${fisher_dir}/text_phone_converted | gzip -c > data/local/rnnlm_train/train_fisher_text.gz
        # combine swbd and fisher texts
        zcat data/local/rnnlm_train/${train_set}_text.gz data/local/rnnlm_train/train_fisher_text.gz |\
            spm_encode --model=${bpemodel}.model --output_format=piece > ${lmdatadir}/train.txt
    else
        zcat data/local/rnnlm_train/${train_set}_text.gz |\
            spm_encode --model=${bpemodel}.model --output_format=piece > ${lmdatadir}/train.txt
    fi
    cut -f 2- -d" " ${dumpdir}/${train_dev}/text_phone_converted |\
            spm_encode --model=${bpemodel}.model --output_format=piece > ${lmdatadir}/valid.txt

    ${cuda_cmd} --gpu ${ngpu} ${lmexpdir}/train.log \
        lm_train.py \
        --config ${rnnlm_config} \
        --ngpu ${ngpu} \
        --backend ${backend} \
        --verbose 1 \
        --outdir ${lmexpdir} \
        --tensorboard-dir tensorboard/${lmexpname} \
        --train-label ${lmdatadir}/train.txt \
        --valid-label ${lmdatadir}/valid.txt \
        --resume ${rnnlm_resume} \
        --dict ${dict}
fi

if [ "${use_fisher_wordlm}" = true ]; then
    lmexpname=train_word_rnnlm_${backend}_fisher
    lmexpdir=exp/${lmexpname}
    # A larger word vocabulary of 67.3K words.
    word_dict=data/lang_phone_bpe/words_fisher.txt
    lmdatadir=data/local/word_rnnlm_train_fisher
else
    lmexpname=train_word_rnnlm_${backend}_swbd
    lmexpdir=exp/${lmexpname}
    word_dict=data/lang_phone_bpe/words.txt
    awk '{ print $1 " " NR }' data/lang_phone_bpe/lexicon_phone_converted.txt > ${word_dict}
    lmdatadir=data/local/word_rnnlm_train_swbd
fi
mkdir -p ${lmexpdir}
echo "word dictionary: ${word_dict}"

if [ ${stage} -le 4 ] && [ ${stop_stage} -ge 4 ]; then
    echo "stage 4: Word LM Preparation"
    mkdir -p data/local/word_rnnlm_train ${lmdatadir}
    cut -f 2- -d" " ${dumpdir}/${train_set}/text | gzip -c > data/local/word_rnnlm_train/${train_set}_text.gz
    if [ "${use_fisher_wordlm}" = true ]; then
        cut -f 2- -d" " ${fisher_dir}/text | gzip -c > data/local/word_rnnlm_train/train_fisher_text.gz
        # combine swbd and fisher texts
        zcat data/local/word_rnnlm_train/${train_set}_text.gz data/local/word_rnnlm_train/train_fisher_text.gz \
            > ${lmdatadir}/train.txt
    else
        zcat data/local/word_rnnlm_train/${train_set}_text.gz > ${lmdatadir}/train.txt
    fi
    cut -f 2- -d" " ${dumpdir}/${train_dev}/text > ${lmdatadir}/valid.txt

    ${cuda_cmd} --gpu ${ngpu} ${lmexpdir}/train.log \
        lm_train.py \
        --config ${word_rnnlm_config} \
        --ngpu ${ngpu} \
        --backend ${backend} \
        --verbose 1 \
        --outdir ${lmexpdir} \
        --tensorboard-dir tensorboard/${lmexpname} \
        --train-label ${lmdatadir}/train.txt \
        --valid-label ${lmdatadir}/valid.txt \
        --resume ${word_rnnlm_resume} \
        --dict ${word_dict}
fi


if [ -z ${tag} ]; then
    expname=train_nodup_${backend}_$(basename ${train_config%.*})
    if [ -n "${preprocess_config}" ]; then
	    expname=${expname}_$(basename ${preprocess_config%.*})
    fi
else
    expname=train_nodup_${backend}_${tag}
fi
expname=${expname}_${bpemode}${nbpe}
expdir=exp/${expname}
mkdir -p ${expdir}

odim=$(wc -l ${dict} | awk '{print $1}')
odim=$(echo "${odim}+2" | bc)
if [ ${stage} -le 5 ] && [ ${stop_stage} -ge 5 ]; then
    echo "stage 5: Network Training"

    python -u -m torch.distributed.launch --nproc_per_node=${ngpu} \
        ../../../espnet/bin/asr_train.py \
        --config ${train_config} \
        --preprocess-conf ${preprocess_config} \
        --epochs ${maxepoch} \
        --ngpu ${ngpu} \
        --backend ${backend} \
        --outdir ${expdir}/results \
        --tensorboard-dir tensorboard/${expname} \
        --debugmode ${debugmode} \
        --dict ${dict} \
        --debugdir ${expdir} \
        --verbose ${verbose} \
        --resume ${resume} \
        --transformer-input-layer ${input_layer} \
        --input-context ${input_context} \
        --input-skiprate ${input_skiprate} \
        --train-sets swbd/swbd1_train,swbd/swbd1_dev \
        --valid-sets swbd/rt03 \
        --idim 83 --odim ${odim} --precomputed-feats-type fbank_pitch \
        --spmodel ${bpemodel}.model \
        --text-filename text_phone_converted

fi


if [ ${stage} -le 6 ] && [ ${stop_stage} -ge 6 ]; then
    echo "stage 6: Decoding"

    lexicon_dict=data/lang_phone_bpe/lexicon_${bpemode}${nbpe}.txt
    paste -d\   <(awk '{ print $1 }' data/lang_phone_bpe/lexicon_phone_converted.txt) \
        <(awk '{ print $2 }' data/lang_phone_bpe/lexicon_phone_converted.txt | spm_encode --model=${bpemodel}.model --output_format=piece) \
        > ${lexicon_dict}

    # Build lexicon in bpe units.
    if [ "${use_fisher_wordlm}" = true ]; then
        lmtag=fisher
    else
        # Use swbd wordlm.
        lmtag=swbd
    fi
    echo "lexicon in BPE: ${lexicon_dict}"

    nj=${ncpu}
    recog_model=model.last${n_average}.avg.best
    average_checkpoints.py --backend ${backend} \
         --snapshots ${expdir}/results/snapshot.ep.* \
         --out ${expdir}/results/${recog_model} \
         --num ${n_average}
    pids=() # initialize pids
    for rtask in ${decode_set}; do
    (
        decode_dir=decode_${rtask}_${recog_model}_$(basename ${decode_config%.*})_${lmtag}_beam${word_rnnlm_beamsize}_weight${word_rnnlm_weight}_bonus${word_rnnlm_bonus}_subweight${subword_rnnlm_weight}

        # split data
        ${decode_cmd} JOB=1:${nj} ${expdir}/${decode_dir}/log/decode.JOB.log \
            asr_recog.py \
            --config ${decode_config} \
            --ngpu 0 \
            --backend ${backend} \
            --preprocess-conf ${preprocess_config} \
            --recog-sets swbd/${rtask} --precomputed-feats-type fbank_pitch \
            --text-filename text_phone_converted \
            --spmodel ${bpemodel}.model \
            --model ${expdir}/results/${recog_model} \
            --word-rnnlm ${lmexpdir}/${lang_model} \
            --rnnlm exp/train_rnnlm_pytorch_lm_${bpemode}${nbpe}/${lang_model} \
            --lexicon-dict ${lexicon_dict} \
            --truth_file ${dumpdir}/${rtask}/text \
            --beam-size ${word_rnnlm_beamsize} \
            --lm-weight ${word_rnnlm_weight} \
            --sublm-weight ${subword_rnnlm_weight} \
            --word-bonus ${word_rnnlm_bonus} \
            --input-context ${input_context} \
            --input-skiprate ${input_skiprate} \
            --num_replicas ${nj} \
            --jobid JOB \
            --result-label ${expdir}/${decode_dir}/data.JOB.json

    # Remove the extra dataset name from speechdataloader' uttids.
    sed -i "s|{${rtask}}||g" ${expdir}/${decode_dir}/data.*.json
    sed -i.org "s|{${rtask}}||g" ${dumpdir}/${rtask}/stm

    # My json already includes the "text" and "rec_text" fields, no need to convert with bpe any more.
    score_sclite_wo_dict.sh --addspkr true ${expdir}/${decode_dir}
    # This is to be consistent with ESPNET's grapheme recipe for scoring.
    sed -i.org 's/\._/ /g; s/\.//g; s/them_1/them/g' ${expdir}/${decode_dir}/ref.wrd.trn
    sed -i.org 's/\._/ /g; s/\.//g; s/them_1/them/g' ${expdir}/${decode_dir}/hyp.wrd.trn

	  if [[ "${decode_dir}" =~ "eval2000" ]]; then
        local/score_sclite.sh ${dumpdir}/eval2000 ${expdir}/${decode_dir}
	  elif [[ "${decode_dir}" =~ "rt03" ]]; then
	      local/score_sclite.sh ${dumpdir}/rt03 ${expdir}/${decode_dir}
	  fi
    ) &
    pids+=($!) # store background pids
    done
    i=0; for pid in "${pids[@]}"; do wait ${pid} || ((++i)); done
    [ ${i} -gt 0 ] && echo "$0: ${i} background jobs are failed." && false
    echo "Finished"
fi


# The lmtag has been updated.
if [ ${stage} -le 7 ] && [ ${stop_stage} -ge 7 ]; then
    echo "stage 7: Joint decoding with char BPE system"

    extended_lexicon_phone_bpe=data/extended_lexicon/extended_lexicon_${bpemode}${nbpe}
    paste -d\   <(awk '{ print $1 }' data/extended_lexicon/lexicon_large_phone_converted.txt) \
        <(awk '{ print $2 }' data/extended_lexicon/lexicon_large_phone_converted.txt | spm_encode --model=${bpemodel}.model --output_format=piece) \
        > ${extended_lexicon_phone_bpe}.txt
    extended_lexicon_char_bpe=data/extended_lexicon/extended_lexicon_bpe${nbpe_char}
    paste -d\   <(awk '{ print $1 }' ${extended_lexicon_phone_bpe}.txt) \
        <(awk '{ print $1 }' ${extended_lexicon_phone_bpe}.txt | sed 's/\._/ /g; s/\.//g; s/them_1/them/g' | spm_encode --model=data/lang_char/train_nodup_bpe${nbpe_char}.model --output_format=piece) \
        > ${extended_lexicon_char_bpe}.txt

    combine_lexicon1_dict=${extended_lexicon_phone_bpe}.txt
    combine_lexicon2_dict=${extended_lexicon_char_bpe}.txt

    if [ "${use_fisher_wordlm}" = true ]; then
        lmtag=combine_fisher
        combine_word_rnnlm=exp/train_word_rnnlm_pytorch_fisher/rnnlm.model.best
    else
        lmtag=combine_swbd
        combine_word_rnnlm=exp/train_word_rnnlm_pytorch_swbd/rnnlm.model.best
    fi

    nj=${ncpu}
    recog_model=model.last${n_average}.avg.best
    average_checkpoints.py --backend ${backend} \
         --snapshots ${expdir}/results/snapshot.ep.* \
         --out ${expdir}/results/${recog_model} \
         --num ${n_average}
    pids=() # initialize pids
    for rtask in ${decode_set}; do
    (
        decode_dir=decode_${rtask}_${recog_model}_$(basename ${decode_config%.*})_${lmtag}_model2weight${model2_weight}_beam${word_rnnlm_beamsize}_weight${word_rnnlm_weight}_bonus${word_rnnlm_bonus}_subweight${subword_rnnlm_weight}

        #### use CPU for decoding
        ngpu=0

        # Weiran: I am assuming both phone and char systems have the same tag (training setup).
        ${decode_cmd} JOB=1:${nj} ${expdir}/${decode_dir}/log/decode.JOB.log \
            asr_recog2.py \
            --config ${decode_config} \
            --ngpu ${ngpu} \
            --backend ${backend} \
            --preprocess-conf ${preprocess_config} \
            --recog-sets swbd/${rtask} --precomputed-feats-type fbank_pitch \
            --text-filename text_phone_converted \
            --spmodel ${bpemodel}.model \
            --truth_file ${dumpdir}/${rtask}/text \
            --beam-size ${word_rnnlm_beamsize} \
            --lm-weight ${word_rnnlm_weight} \
            --word-bonus ${word_rnnlm_bonus} \
            --word-rnnlm ${combine_word_rnnlm} \
            --sublm-weight ${subword_rnnlm_weight} \
            --model1 ${expdir}/results/${recog_model} \
            --rnnlm1 exp/train_rnnlm_pytorch_lm_${bpemode}${nbpe}/${lang_model} \
            --lexicon1-dict ${combine_lexicon1_dict} \
            --model2-weight ${model2_weight} \
            --model2 exp/train_nodup_pytorch_${tag}_bpe${nbpe_char}/results/model.last10.avg.best \
            --rnnlm2 exp/train_rnnlm_pytorch_lm_bpe${nbpe_char}/rnnlm.model.best \
            --lexicon2-dict ${combine_lexicon2_dict} \
            --input-context ${input_context} \
            --input-skiprate ${input_skiprate} \
            --num_replicas ${nj} \
            --jobid JOB \
            --result-label ${expdir}/${decode_dir}/data.JOB.json

        # Remove the extra dataset name from speechdataloader' uttids.
        sed -i "s|{${rtask}}||g" ${expdir}/${decode_dir}/data.*.json
        sed -i.org "s|{${rtask}}||g" ${dumpdir}/${rtask}/stm

        # Weiran: my json already includes the "text" and "rec_text" fields, no need to convert with bpe any more.
        score_sclite_wo_dict.sh --addspkr true ${expdir}/${decode_dir}
        # Weiran: this is to be consistent with ESPNET's grapheme recipe for scoring.
        sed -i.org 's/\._/ /g; s/\.//g; s/them_1/them/g' ${expdir}/${decode_dir}/ref.wrd.trn
        sed -i.org 's/\._/ /g; s/\.//g; s/them_1/them/g' ${expdir}/${decode_dir}/hyp.wrd.trn

	      if [[ "${decode_dir}" =~ "eval2000" ]]; then
            local/score_sclite.sh ${dumpdir}/eval2000 ${expdir}/${decode_dir}
	      elif [[ "${decode_dir}" =~ "rt03" ]]; then
	          local/score_sclite.sh ${dumpdir}/rt03 ${expdir}/${decode_dir}
	      fi
    ) &
    pids+=($!) # store background pids
    done
    i=0; for pid in "${pids[@]}"; do wait ${pid} || ((++i)); done
    [ ${i} -gt 0 ] && echo "$0: ${i} background jobs are failed." && false
    echo "Finished"
fi

# Phone and char sets are in data/local/dict_phone/
# Phone BPE modes/units and translated lexicon are in data/lang_phone_bpe/
#
# For data loader
# ./run_phone_bpe.sh --stage 4 --stop_stage 4 --ngpu 1 --gpuid 0 --tag speechdataloader
# ./run_phone_bpe.sh --stage 5 --stop_stage 5 --ngpu 8 --gpuid 0,1,2,3,4,5,6,7 --train_config conf/train_largestoc5.yaml --tag speechdataloader
# ./run_phone_bpe.sh --stage 6 --stop_stage 6 --tag speechdataloader --decode_set eval2000
# ./run_phone_bpe.sh --stage 7 --stop_stage 7 --tag speechdataloader --decode_set eval2000