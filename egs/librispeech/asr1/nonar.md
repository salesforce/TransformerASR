# Non-autoregressive decoding

Traditional beam search decoders are sophisticated, and the left-to-right nature requires careful implementation for them to be time-efficient. Non-autoregressive decoding methods produce multiple output tokens in parallel, and in a sense, replaces complicated search algorithms with a neural architecture.


## Align-refine

In this package, we implement the Align-refine approach by [1]. The basic idea is to use a CTC module to perform greedy decoding, and refine the CTC greedy alignment with another transformer-based decoder module in B>=1 steps, where each step transforms a complete alignment to another complete alignment. The final alignment is collapsed into a label sequence according to the standard CTC token-level topology (removing repetitions and then blanks) to yield the final label sequence hypothesis.   

* The decoder module takes as input a complete alignment, which contains one label (including both real labels and the `<blank>`) per frame.

* Similar to the decoder module in a usual Attention model, the module first performs *self-attention* among the (discrete) alignment, and then use the resulting (per-frame) representation to perform *cross-attention* over the encoder outputs, and finally outputs per-frame posterior probabilities. The difference between this module and the decoder in a usual Attention model is that the latter takes as input the *label sequence* rather than *the alignment*. From the per-frame posteriors, we obtain a new greedy alignment for the next refinement step. Refinement of the alignment potentially allows complicated edits (insertion, deletion, substitution) for the collapsed label sequences. This is in contrast to the Imputer approach by [1], which gradually removes masks over the alignment, not allowing modifications to the already revealed frames.

* Both the CTC module and each step of the decoder is trained with the CTC objective which marginalizes all possible alignments, although we only use the greedy alignment for each decoding step. Both the CTC step and the refinement steps are trained jointly, so that the decoder module is adapted to the specific CTC module. However, gradient is not back-propagated through all these steps during training.  

* Recall that the greedy alignment is generated by taking the most probable token from the per-frame posteriors. This can be done for all frames in parallel, and is thus fully non-autoregressive.
  

## Results

We provide the training and decoding recipes of non-autoregressive decoding for the `Librispeech` corpus. Here are some example commands: 
 
```bash

# Prepare BPE dictionary
./run_realigner.sh --stage 2 --stop_stage 2

# Acoustic model training 
./run_realigner.sh --stage 3 --stop_stage 3 --ngpu 8 --gpuid 0,1,2,3,4,5,6,7 --tag realigner

# Decoding
./run_realigner.sh --stage 4 --stop_stage 4 --tag realigner

```

We obtain the following WER results on test-clean and test-other using a model of 12 encoder layers, 4 decoder layers, attention_dim=512, and B=4 refinement steps. We also include results from the literature with similar model sizes and the same token set--400 BPEs.

Finally, we provide an ablation study of the number of decoding steps. By default, our recipe uses the same number of decoding steps for training and test. The model is trained with 4 decoding steps, and here we show WERs obtained with 1,2,3,4 steps at test time. More steps tend to improve over one step, until the performance improvement saturates.  

|                                    |  test-clean (%)  |  test-other (%)  | 
| :-------------------------------   |  :------------:  |  :------------:  |
| Imputer ([1], no SpecAugment)      |  4.0             |  11.1            |
| Align-refine [2]                   |  3.6             |  9.0             |
| Our implementation (# dec. step=1) |  3.8             |  9.4             |
| Our implementation (# dec. step=2) |  3.5             |  8.8             |
| Our implementation (# dec. step=3) |  3.5             |  8.7             |
| Our implementation (# dec. step=4) |  **3.5**         |  **8.7**         |


## References

[1] Ethan A. Chi, Julian Salazar, and Katrin Kirchhoff, "Align-Refine: Non-Autoregressive Speech Recognition via Iterative Realignment". *ArXiv:2010.14233 [eess.AS]*, 2020.

[2] William Chan, Chitwan Saharia, Geoffrey Hinton, Mohammad Norouzi, and Navdeep Jaitly, "Imputer: Sequence Modelling via Imputation and Dynamic Programming". *ArXiv:2002.08926 [eess.AS]*, 2020.
